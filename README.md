# ERD Detector: Single-Trial Event-Related Desynchronization Detection

> **Note**: This README uses UTF-8 encoding for Greek letters (Âµ, Î², Ïƒ). If you see garbled characters, view this file in a UTF-8 compatible editor or see ASCII equivalents in parentheses.

Single-trial ERD detection using Hilbert-Huang Transform for Brain-Computer Interface applications.

## Overview

This package implements the methodology described in your thesis for detecting Event-Related Desynchronization (ERD) in EEG signals **without machine learning calibration**.

### Algorithm Components

1. **Preprocessing**
   - Bandpass filter (8-30 Hz) to isolate Âµ (mu) and Î² (beta) rhythms
   - Laplacian spatial filter for C3/C4 to enhance local activity
   - Artifact rejection using amplitude thresholding (Â±100ÂµV)

2. **Hilbert-Huang Transform (HHT)**
   - Empirical Mode Decomposition (EMD) â†’ Intrinsic Mode Functions (IMFs)
   - Spectral IMF selection (60% power in 8-30 Hz band)
   - Hilbert Transform â†’ Instantaneous amplitude
   - Power calculation (amplitudeÂ²)

3. **ERD Detection**
   - Baseline calculation from reference channels (O1, O2, Fz) during [-3s, -1s]
   - Sliding window (200ms, 50ms step) through task period [0s, +4s]
   - Normalize motor channels (C3, C4): z = (P - Î¼) / Ïƒ (sigma)
   - Detect ERD when z â‰¤ -2Ïƒ (sigma) in â‰¥2 motor channels

### Key Features

âœ… **No Calibration** - Uses neurophysiological thresholds  
âœ… **Single-Trial** - Works on individual trials  
âœ… **Low Latency** - Target â‰¤200ms processing time  
âœ… **High Accuracy** - Target â‰¥80% detection rate  

## Project Structure

```
erd-detector/
â”œâ”€â”€ erd_detector/           # Main package
â”‚   â”œâ”€â”€ __init__.py        # Package initialization
â”‚   â”œâ”€â”€ utils.py           # Data loading (OpenBMI)
â”‚   â”œâ”€â”€ preprocessing.py   # Filtering & artifacts
â”‚   â”œâ”€â”€ hht.py            # EMD + Hilbert Transform
â”‚   â”œâ”€â”€ detection.py      # ERD detection algorithm
â”‚   â”œâ”€â”€ metrics.py        # Performance evaluation
â”‚   â””â”€â”€ visualization.py  # Plotting functions
â”œâ”€â”€ scripts/               # Batch processing
â”‚   â”œâ”€â”€ download_data.py  # Download from GigaDB
â”‚   â”œâ”€â”€ process_all.py    # Process 54 subjects
â”‚   â”œâ”€â”€ analyze.py        # Compute metrics
â”‚   â””â”€â”€ visualize.py      # Generate figures
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ examples/              # Usage examples
â”œâ”€â”€ results/               # Output directory
â”‚   â”œâ”€â”€ figures/          # Generated plots
â”‚   â”œâ”€â”€ data/             # Processed results
â”‚   â””â”€â”€ reports/          # Analysis summaries
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ setup.py              # Package installation
â””â”€â”€ README.md             # This file
```

## Installation

### Local Setup (For Testing)

```bash
cd /c/Users/Thiago\ Doria/Desktop/EEG/erd-detector
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
pip install -e .
```

### Cloud Setup (For Full Processing)

The dataset is ~209 GB, so cloud processing is required.

**GCP Setup (Recommended - Hong Kong region closest to GigaDB):**

```bash
# 1. Create GCP project
gcloud projects create erd-research-2025

# 2. Enable Compute Engine
gcloud services enable compute.googleapis.com

# 3. Create VM
gcloud compute instances create erd-vm \
    --project=erd-research-2025 \
    --zone=asia-east2-a \
    --machine-type=n1-highmem-16 \
    --boot-disk-size=50GB \
    --boot-disk-type=pd-ssd

# 4. Create data disk
gcloud compute disks create erd-data \
    --project=erd-research-2025 \
    --zone=asia-east2-a \
    --size=500GB \
    --type=pd-ssd

# 5. Attach disk
gcloud compute instances attach-disk erd-vm \
    --disk=erd-data \
    --zone=asia-east2-a

# 6. SSH and setup
gcloud compute ssh erd-vm --zone=asia-east2-a
```

## Implementation Status

### âœ… Completed
- [x] **Project structure** - Complete directory layout
- [x] **Documentation** - README, CLOUD_SETUP, requirements.txt, setup.py
- [x] **Git repository** - Initialized with LICENSE and .gitignore
- [x] **utils.py** - FULLY IMPLEMENTED with proper channel parsing
  - `load_openbmi_data()` - Load OpenBMI .mat files
  - `extract_trial()` - Extract trial windows
  - `get_channel_indices()` - Channel lookup
  - `create_mne_raw()` - MNE conversion
- [x] **preprocessing.py** - FULLY IMPLEMENTED
  - `bandpass_filter()` - Butterworth 8-30 Hz for mu/beta isolation
  - `laplacian_filter()` - Surface Laplacian for C3/C4 motor channels
  - `reject_artifacts()` - Amplitude thresholding (+/-100 microV)
  - `preprocess_trial()` - Complete 4-stage pipeline
- [x] **hht.py** - FULLY IMPLEMENTED
  - `empirical_mode_decomposition()` - EMD using PyEMD
  - `select_imfs_spectral()` - IMF selection (60% power in 8-30 Hz)
  - `hilbert_transform()` - Instantaneous amplitude and frequency
  - `instantaneous_power()` - Power calculation
  - `process_channel_hht()` - Complete HHT pipeline
- [x] **detection.py** - FULLY IMPLEMENTED
  - `calculate_baseline()` - Baseline from reference channels (O1, O2, Fz)
  - `detect_erd_sliding_window()` - Sliding window with -2Ïƒ threshold
  - `ERDDetector` class - Complete end-to-end pipeline

### ğŸ”¨ In Progress
- [ ] **metrics.py** - Performance evaluation
- [ ] **visualization.py** - Plotting functions
- [ ] **scripts/** - Data download and batch processing

### ğŸ“‹ Planned
- [ ] Unit tests
- [ ] Cloud deployment
- [ ] Full dataset processing
- [ ] Results and analysis

**Current Focus**: Core algorithm complete! Next: batch processing scripts and metrics

## Usage

### Quick Start

**Note**: Core algorithm is fully implemented! You'll need to install dependencies first:
```bash
pip install -r requirements.txt
```

```python
from erd_detector import ERDDetector
from erd_detector.utils import load_openbmi_data, extract_trial

# Initialize detector with thesis defaults
detector = ERDDetector(
    motor_channels=['C3', 'C4'],
    reference_channels=['O1', 'O2', 'Fz'],
    threshold_sigma=-2.0,       # Thesis default: -2Ïƒ
    min_channels=2              # Require both C3 and C4
)

# Load data
data = load_openbmi_data(subject_id=1, session=1, data_type='train')

# Process single trial
event_time = data['events'][0]
trial_data = extract_trial(data['data'], event_time, data['fs'])

# Detect ERD
result = detector.process_trial(
    trial_data,
    data['channels'],
    data['fs']
)

# Check result
if result['detected']:
    print(f"âœ“ ERD detected at {result['onset_time']:.3f}s")
    print(f"  Latency: {result['latency']*1000:.1f}ms")
else:
    print("âœ— No ERD detected")
```

### What's Implemented

âœ… **Full ERD detection pipeline** - All core modules complete:
- Data loading (`utils.py`)
- Preprocessing (`preprocessing.py`)
- HHT analysis (`hht.py`)
- ERD detection (`detection.py`)

âš ï¸ **Still needed**:
- Batch processing scripts (for all 54 subjects)
- Performance metrics (`metrics.py`)
- Visualization tools (`visualization.py`)
- Unit tests

### Batch Processing (To Be Implemented)

These scripts will process all 54 subjects:

```bash
# Download OpenBMI dataset (to be implemented)
python scripts/download_data.py

# Process all 54 subjects (to be implemented)
python scripts/process_all.py

# Analyze results (to be implemented)
python scripts/analyze.py

# Generate figures (to be implemented)
python scripts/visualize.py
```

## Dataset

**OpenBMI Motor Imagery Dataset**
- 54 subjects Ã— 2 sessions
- 200 trials per session (100 train, 100 test)
- 62 EEG channels @ 1000 Hz
- Motor imagery: left hand vs right hand
- Total size: ~209 GB

**Citation:**
Lee, M.H., et al. (2019). EEG dataset and OpenBMI toolbox for three BCI paradigms: an investigation into BCI illiteracy. GigaScience, 8(5).

**Download:** https://gigadb.org/dataset/100542

## Results (To Be Completed)

Targets from thesis:
- Detection rate: â‰¥80%
- Latency: â‰¤200ms
- Comparison: CSP+LDA baseline = 71.1%

Results will be populated after processing all subjects.

## Next Steps

See [NEXT_STEPS.md](NEXT_STEPS.md) for detailed implementation roadmap.

1. **Complete Core Modules** - Implement preprocessing, HHT, detection
2. **Create Batch Scripts** - Data download and processing scripts
3. **Local Testing** - Test on sample data
4. **Cloud Deployment** - Set up GCP VM and download full dataset
4. **Batch Processing** - Process all 54 subjects
5. **Analysis** - Compute metrics and compare with baseline
6. **Visualization** - Generate all figures for thesis
7. **Documentation** - Write technical report

## Development

### Running Tests

```bash
pytest tests/ -v
```

### Code Style

All code includes:
- Line-by-line comments explaining logic
- Docstrings with mathematical formulas (LaTeX)
- Type hints for clarity
- Neurophysiological justifications

## Citation

If you use this package, please cite your thesis:

```bibtex
@mastersthesis{fonseca2025erd,
  title={Processamento de sinais de EEG para detecÃ§Ã£o de ERD em baixa latÃªncia para controle de interfaces cÃ©rebro-computador (BCI)},
  author={Fonseca, Lucas Pereira da and Doria, Thiago Anversa Sampaio},
  year={2025},
  school={Universidade de SÃ£o Paulo}
}
```

## License

MIT License - See LICENSE file

## Contact

- Lucas Pereira da Fonseca
- Thiago Anversa Sampaio Doria
- Advisor: Prof. Arturo Forner-Cordero
- Institution: Escola PolitÃ©cnica, Universidade de SÃ£o Paulo

## Acknowledgments

- Prof. Arturo Forner-Cordero for guidance and introducing this research topic
- Bruna and AndrÃ© for research support and valuable insights
- OpenBMI team for providing the dataset
