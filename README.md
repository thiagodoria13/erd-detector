# ERD Detector: Single-Trial Event-Related Desynchronization Detection

> **Note**: This README uses UTF-8 encoding for Greek letters (¬µ, Œ≤, œÉ). If you see garbled characters, view this file in a UTF-8 compatible editor or see ASCII equivalents in parentheses.

Single-trial ERD detection using Hilbert-Huang Transform for Brain-Computer Interface applications.

## Overview

This package implements the methodology described in your thesis for detecting Event-Related Desynchronization (ERD) in EEG signals **without machine learning calibration**.

### Algorithm Components

1. **Preprocessing**
   - Bandpass filter (8-30 Hz) to isolate ¬µ (mu) and Œ≤ (beta) rhythms
   - Laplacian spatial filter for C3/C4 to enhance local activity
   - Artifact rejection using amplitude thresholding (¬±100¬µV)

2. **Hilbert-Huang Transform (HHT)**
   - Empirical Mode Decomposition (EMD) ‚Üí Intrinsic Mode Functions (IMFs)
   - Spectral IMF selection (60% power in 8-30 Hz band)
   - Hilbert Transform ‚Üí Instantaneous amplitude
   - Power calculation (amplitude¬≤)

3. **ERD Detection**
   - Baseline calculation from reference channels (O1, O2, Fz) during [-3s, -1s]
   - Sliding window (200ms, 50ms step) through task period [0s, +4s]
   - Normalize motor channels (C3, C4): z = (P - Œº) / œÉ (sigma)
   - Detect ERD when z ‚â§ -2œÉ (sigma) in ‚â•2 motor channels

### Key Features

‚úÖ **No Calibration** - Uses neurophysiological thresholds  
‚úÖ **Single-Trial** - Works on individual trials  
‚úÖ **Low Latency** - Target ‚â§200ms processing time  
‚úÖ **High Accuracy** - Target ‚â•80% detection rate  

## Project Structure

```
erd-detector/
‚îú‚îÄ‚îÄ erd_detector/           # Main package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py        # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ utils.py           # Data loading (OpenBMI)
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py   # Filtering & artifacts
‚îÇ   ‚îú‚îÄ‚îÄ hht.py            # EMD + Hilbert Transform
‚îÇ   ‚îú‚îÄ‚îÄ detection.py      # ERD detection algorithm
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py        # Performance evaluation
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py  # Plotting functions
‚îú‚îÄ‚îÄ scripts/               # Batch processing
‚îÇ   ‚îú‚îÄ‚îÄ download_data.py  # Download from GigaDB
‚îÇ   ‚îú‚îÄ‚îÄ process_all.py    # Process 54 subjects
‚îÇ   ‚îú‚îÄ‚îÄ analyze.py        # Compute metrics
‚îÇ   ‚îî‚îÄ‚îÄ visualize.py      # Generate figures
‚îú‚îÄ‚îÄ tests/                 # Unit tests
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ examples/              # Usage examples
‚îú‚îÄ‚îÄ results/               # Output directory
‚îÇ   ‚îú‚îÄ‚îÄ figures/          # Generated plots
‚îÇ   ‚îú‚îÄ‚îÄ data/             # Processed results
‚îÇ   ‚îî‚îÄ‚îÄ reports/          # Analysis summaries
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ setup.py              # Package installation
‚îî‚îÄ‚îÄ README.md             # This file
```

## Installation

### Local Setup (For Testing)

**Automated Setup (Recommended):**

Windows (CMD):
```cmd
setup_local_test.bat
```

Git Bash / Linux / Mac:
```bash
bash setup_local_test.sh
```

**Manual Setup:**
```bash
# Create virtual environment
python -m venv .venv

# Activate (choose one based on your system)
.venv\Scripts\activate        # Windows CMD
source .venv/Scripts/activate  # Git Bash on Windows
source .venv/bin/activate      # Linux/Mac

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Optional: Install package in editable mode
pip install -e .
```

### Cloud Setup (For Full Processing)

The dataset is ~209 GB, so cloud processing is required.

**GCP Setup (Recommended - Hong Kong region closest to GigaDB):**

```bash
# 1. Create GCP project
gcloud projects create erd-research-2025

# 2. Enable Compute Engine
gcloud services enable compute.googleapis.com

# 3. Create VM
gcloud compute instances create erd-vm \
    --project=erd-research-2025 \
    --zone=asia-east2-a \
    --machine-type=n1-highmem-16 \
    --boot-disk-size=50GB \
    --boot-disk-type=pd-ssd

# 4. Create data disk
gcloud compute disks create erd-data \
    --project=erd-research-2025 \
    --zone=asia-east2-a \
    --size=500GB \
    --type=pd-ssd

# 5. Attach disk
gcloud compute instances attach-disk erd-vm \
    --disk=erd-data \
    --zone=asia-east2-a

# 6. SSH and setup
gcloud compute ssh erd-vm --zone=asia-east2-a
```

## Implementation Status

### ‚úÖ Completed
- [x] **Project structure** - Complete directory layout
- [x] **Documentation** - README, CLOUD_SETUP, requirements.txt, setup.py
- [x] **Git repository** - Initialized with LICENSE and .gitignore
- [x] **utils.py** - FULLY IMPLEMENTED with proper channel parsing
  - `load_openbmi_data()` - Load OpenBMI .mat files
  - `extract_trial()` - Extract trial windows
  - `get_channel_indices()` - Channel lookup
  - `create_mne_raw()` - MNE conversion
- [x] **preprocessing.py** - FULLY IMPLEMENTED
  - `bandpass_filter()` - Butterworth 8-30 Hz for mu/beta isolation
  - `laplacian_filter()` - Surface Laplacian for C3/C4 motor channels
  - `reject_artifacts()` - Amplitude thresholding (+/-100 microV)
  - `preprocess_trial()` - Complete 4-stage pipeline
- [x] **hht.py** - FULLY IMPLEMENTED
  - `empirical_mode_decomposition()` - EMD using the `EMD-signal` (PyEMD) package
  - `select_imfs_spectral()` - IMF selection (60% power in 8-30 Hz)
  - `hilbert_transform()` - Instantaneous amplitude and frequency
  - `instantaneous_power()` - Power calculation
  - `process_channel_hht()` - Complete HHT pipeline
- [x] **detection.py** - FULLY IMPLEMENTED
  - `calculate_baseline()` - Baseline from reference channels (O1, O2, Fz)
  - `detect_erd_sliding_window()` - Sliding window with -2œÉ threshold
  - `ERDDetector` class - Complete end-to-end pipeline

### üî® In Progress
- [ ] **metrics.py** - Performance evaluation
- [ ] **visualization.py** - Plotting functions
- [ ] **scripts/** - Data download and batch processing

### üìã Planned
- [ ] Unit tests
- [ ] Cloud deployment
- [ ] Full dataset processing
- [ ] Results and analysis

**Current Focus**: Core algorithm complete! Next: batch processing scripts and metrics

## Usage

### Quick Start

**Note**: Core algorithm is fully implemented! You'll need to install dependencies first:
```bash
pip install -r requirements.txt
```

> **Trial format**: All functions assume each trial array is shaped
> `(samples, channels)` (as returned by `extract_trial`) and that the first
> sample occurs **-3‚ÄØs relative to the cue** (the default extraction window
> [-3‚ÄØs, +4‚ÄØs]). If you use a different window, pass the appropriate
> `trial_start_time` to `ERDDetector`.

```python
from erd_detector import ERDDetector
from erd_detector.utils import load_openbmi_data, extract_trial

# Initialize detector with thesis defaults
detector = ERDDetector(
    motor_channels=['C3', 'C4'],
    reference_channels=['O1', 'O2', 'Fz'],
    threshold_sigma=-2.0,       # Thesis default: -2œÉ
    min_channels=2              # Require both C3 and C4
)

# Load data
data = load_openbmi_data(subject_id=1, session=1, data_type='train')

# Process single trial
event_time = data['events'][0]
trial_data = extract_trial(data['data'], event_time, data['fs'])

# Detect ERD
result = detector.process_trial(
    trial_data,
    data['channels'],
    data['fs']
)

# Check result
if result['detected']:
    print(f"‚úì ERD detected at {result['onset_time']:.3f}s")
    print(f"  Latency: {result['latency']*1000:.1f}ms")
else:
    print("‚úó No ERD detected")
```

### Local Testing with Real Data

Test the complete pipeline with **real OpenBMI EEG data** (small sample, ~4-8 GB):

**Step 1: Download sample data**
```bash
python download_sample_data.py
```

This provides instructions to download 1-2 subjects from the OpenBMI dataset.
Files to download manually:
- `sess01_subj01_EEG_MI.mat` (~2 GB)
- `sess02_subj01_EEG_MI.mat` (~2 GB)

Download from: https://gigadb.org/dataset/100542
Save to: `data/openbmi_sample/`

**Step 2: Run tests**
```bash
python test_local.py
```

The test script:
- Loads real EEG trials from OpenBMI dataset
- Processes 5 trials through complete pipeline
- Shows detection results and statistics
- Creates visualization plots for each trial

**Expected output:**
```
[1/5] Checking for OpenBMI data files...
  ‚úì Found 2 data file(s)
[2/5] Loading EEG data...
  ‚úì Loaded 100 trials
[3/5] Initializing ERD detector...
[4/5] Processing trials...
  Trial 1/5:
    ‚úì ERD detected at 1.xxx s (latency: xxx ms)
[5/5] Summary:
  ERD detected: X/5 trials
  Average latency: XXX ms
```

This validates the pipeline on real motor imagery data.

### What's Implemented

‚úÖ **Full ERD detection pipeline** - All core modules complete:
- Data loading (`utils.py`)
- Preprocessing (`preprocessing.py`)
- HHT analysis (`hht.py`)
- ERD detection (`detection.py`)

‚ö†Ô∏è **Still needed**:
- Batch processing scripts (for all 54 subjects)
- Performance metrics (`metrics.py`)
- Visualization tools (`visualization.py`)
- Unit tests

### Batch Processing (To Be Implemented)

These scripts will process all 54 subjects:

```bash
# Download OpenBMI dataset (to be implemented)
python scripts/download_data.py

# Process all 54 subjects (to be implemented)
python scripts/process_all.py

# Analyze results (to be implemented)
python scripts/analyze.py

# Generate figures (to be implemented)
python scripts/visualize.py
```

## Dataset

**OpenBMI Motor Imagery Dataset**
- 54 subjects √ó 2 sessions
- 200 trials per session (100 train, 100 test)
- 62 EEG channels @ 1000 Hz
- Motor imagery: left hand vs right hand
- Total size: ~209 GB

**Citation:**
Lee, M.H., et al. (2019). EEG dataset and OpenBMI toolbox for three BCI paradigms: an investigation into BCI illiteracy. GigaScience, 8(5).

**Download:** https://gigadb.org/dataset/100542

## Results (To Be Completed)

Targets from thesis:
- Detection rate: ‚â•80%
- Latency: ‚â§200ms
- Comparison: CSP+LDA baseline = 71.1%

Results will be populated after processing all subjects.

## Next Steps

See [NEXT_STEPS.md](NEXT_STEPS.md) for detailed implementation roadmap.

1. **Complete Core Modules** - Implement preprocessing, HHT, detection
2. **Create Batch Scripts** - Data download and processing scripts
3. **Local Testing** - Test on sample data
4. **Cloud Deployment** - Set up GCP VM and download full dataset
4. **Batch Processing** - Process all 54 subjects
5. **Analysis** - Compute metrics and compare with baseline
6. **Visualization** - Generate all figures for thesis
7. **Documentation** - Write technical report

## Development

### Running Tests

```bash
pytest tests/ -v
```

### Code Style

All code includes:
- Line-by-line comments explaining logic
- Docstrings with mathematical formulas (LaTeX)
- Type hints for clarity
- Neurophysiological justifications

## Citation

If you use this package, please cite your thesis:

```bibtex
@mastersthesis{fonseca2025erd,
  title={Processamento de sinais de EEG para detec√ß√£o de ERD em baixa lat√™ncia para controle de interfaces c√©rebro-computador (BCI)},
  author={Fonseca, Lucas Pereira da and Doria, Thiago Anversa Sampaio},
  year={2025},
  school={Universidade de S√£o Paulo}
}
```

## License

MIT License - See LICENSE file

## Contact

- Lucas Pereira da Fonseca
- Thiago Anversa Sampaio Doria
- Advisor: Prof. Arturo Forner-Cordero
- Institution: Escola Polit√©cnica, Universidade de S√£o Paulo

## Acknowledgments

- Prof. Arturo Forner-Cordero for guidance and introducing this research topic
- Bruna and Andr√© for research support and valuable insights
- OpenBMI team for providing the dataset
